{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte A)**\n",
    "\n",
    "#### **Memória Compartilhada**\n",
    "- **Descrição**:\n",
    "  - Todos os processadores compartilham o mesmo espaço de memória.\n",
    "  - Um processo pode acessar diretamente os dados de outro, pois a memória é global.\n",
    "  - Exemplo: Sistemas multiprocessadores com memória principal compartilhada.\n",
    "\n",
    "- **Prós**:\n",
    "  - Comunicação rápida, pois os dados estão na mesma memória.\n",
    "  - Mais fácil de programar, já que não é necessário explicitamente mover dados entre processadores.\n",
    "  - Ideal para sistemas com poucos núcleos.\n",
    "\n",
    "- **Contras**:\n",
    "  - Não escala bem para um grande número de processadores devido à contenção de memória (barramento).\n",
    "  - Pode haver problemas de concorrência (condição de corrida) se o acesso à memória não for controlado adequadamente.\n",
    "\n",
    "#### **Memória Distribuída**\n",
    "- **Descrição**:\n",
    "  - Cada processador possui sua própria memória local, e a comunicação ocorre por troca de mensagens.\n",
    "  - Exemplo: Clusters de computadores.\n",
    "\n",
    "- **Prós**:\n",
    "  - Escala bem para um grande número de processadores.\n",
    "  - Cada nó pode ser otimizado para acessar sua própria memória local sem interferência.\n",
    "\n",
    "- **Contras**:\n",
    "  - A comunicação entre processadores é mais lenta devido à troca de mensagens.\n",
    "  - A programação é mais complexa, pois os dados precisam ser explicitamente movidos entre os nós.\n",
    "\n",
    "#### **Bibliotecas e Modelos**\n",
    "1. **OpenMP**:\n",
    "   - Modelo: **Memória Compartilhada**.\n",
    "   - Os threads compartilham o mesmo espaço de memória e utilizam sincronização para evitar conflitos.\n",
    "\n",
    "2. **MPI**:\n",
    "   - Modelo: **Memória Distribuída**.\n",
    "   - Cada processo tem sua própria memória, e a comunicação é feita por troca de mensagens entre os processos.\n",
    "\n",
    "3. **Thrust**:\n",
    "   - Modelo: **Memória Compartilhada em GPU**.\n",
    "   - A GPU utiliza um modelo de memória hierárquico, onde blocos de threads compartilham memória dentro de um SM (Streaming Multiprocessor), mas cada bloco é independente e comunica-se com a memória global.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte B)**\n",
    "\n",
    "#### **O que é Escalonamento Dinâmico?**\n",
    "- O escalonamento dinâmico em OpenMP é um mecanismo de atribuição de tarefas em que as iterações do loop são atribuídas aos threads à medida que elas se tornam disponíveis.\n",
    "- Em outras palavras, as tarefas não são distribuídas de forma fixa no início do loop, mas atribuídas dinamicamente com base na disponibilidade dos threads durante a execução.\n",
    "\n",
    "#### **Como Configurar?**\n",
    "- Em OpenMP, o escalonamento dinâmico é ativado com a cláusula `schedule(dynamic, chunk_size)`:\n",
    "  ```cpp\n",
    "  #pragma omp parallel for schedule(dynamic, 10)\n",
    "  for (int i = 0; i < N; i++) {\n",
    "      // Trabalho para cada iteração\n",
    "  }\n",
    "  ```\n",
    "- O parâmetro `chunk_size` define o número de iterações atribuídas a um thread de cada vez.\n",
    "\n",
    "#### **Vantagens do Escalonamento Dinâmico**\n",
    "1. **Balanceamento de Carga**:\n",
    "   - Em aplicações onde o trabalho de cada iteração varia, o escalonamento dinâmico evita que threads fiquem ociosos enquanto outros estão sobrecarregados.\n",
    "\n",
    "2. **Aproveitamento Máximo dos Recursos**:\n",
    "   - Threads que terminam suas tarefas mais rapidamente podem assumir novas tarefas, otimizando o uso dos recursos disponíveis.\n",
    "\n",
    "3. **Flexibilidade**:\n",
    "   - É ideal para problemas onde não é possível prever a carga de trabalho de cada iteração, como simulações, processamento de dados heterogêneos ou algoritmos adaptativos.\n",
    "\n",
    "#### **Exemplo de Aplicação**\n",
    "Considere um loop em que cada iteração processa um arquivo de tamanho variável:\n",
    "```cpp\n",
    "#pragma omp parallel for schedule(dynamic, 1)\n",
    "for (int i = 0; i < num_files; i++) {\n",
    "    process_file(files[i]); // Tamanho de arquivos varia\n",
    "}\n",
    "```\n",
    "Neste caso:\n",
    "- Tamanhos diferentes de arquivos resultam em tempos de processamento variáveis.\n",
    "- O escalonamento dinâmico garante que threads mais rápidos processem mais arquivos, evitando desperdício de tempo.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
