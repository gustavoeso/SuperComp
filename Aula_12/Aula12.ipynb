{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Aula 12: Funções Customizadas e Otimização com Fusion Kernel"
      ],
      "metadata": {
        "id": "z-ScnaSvHlQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 1: Cálculo Saxpy"
      ],
      "metadata": {
        "id": "FrK7W2DsHnyV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3iRAeuVHL6I",
        "outputId": "ce5cdf1e-d31d-4c22-a085-54d73a0493e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting saxpy.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile saxpy.cu\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <iostream>\n",
        "#include <chrono>   // Biblioteca para medir o tempo\n",
        "#include <cstdlib>  // Para a função rand()\n",
        "\n",
        "// Functor para calcular Saxpy na GPU\n",
        "struct saxpy\n",
        "{\n",
        "    int a;\n",
        "    saxpy(int a_) : a(a_) {}\n",
        "\n",
        "    __host__ __device__\n",
        "    double operator()(const double& x, const double& y) const {\n",
        "        return a * x + y;\n",
        "    }\n",
        "};\n",
        "\n",
        "// Função para calcular Saxpy na CPU\n",
        "void saxpy_cpu(const std::vector<double>& x, const std::vector<double>& y, std::vector<double>& z, int a) {\n",
        "    for (size_t i = 0; i < x.size(); ++i) {\n",
        "        z[i] = a * x[i] + y[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 100000000;  // Tamanho grande para comparação de performance\n",
        "    int a = 2;\n",
        "\n",
        "    // Inicializar vetores para a CPU\n",
        "    std::vector<double> h_x_cpu(N), h_y_cpu(N), h_z_cpu(N);\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        h_x_cpu[i] = rand() % 100;\n",
        "        h_y_cpu[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    // Medir tempo para a CPU\n",
        "    auto start_cpu = std::chrono::high_resolution_clock::now();\n",
        "    saxpy_cpu(h_x_cpu, h_y_cpu, h_z_cpu, a);\n",
        "    auto end_cpu = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double> duration_cpu = end_cpu - start_cpu;\n",
        "    std::cout << \"Tempo de execução na CPU: \" << duration_cpu.count() << \" segundos\" << std::endl;\n",
        "\n",
        "    // Inicializar vetores para a GPU\n",
        "    thrust::host_vector<double> h_x(N), h_y(N), h_z(N);\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        h_x[i] = h_x_cpu[i];\n",
        "        h_y[i] = h_y_cpu[i];\n",
        "    }\n",
        "\n",
        "    // Transferir vetores para a GPU\n",
        "    thrust::device_vector<double> d_x = h_x;\n",
        "    thrust::device_vector<double> d_y = h_y;\n",
        "    thrust::device_vector<double> d_z(N);\n",
        "\n",
        "    // Medir tempo para a GPU\n",
        "    auto start_gpu = std::chrono::high_resolution_clock::now();\n",
        "    thrust::transform(d_x.begin(), d_x.end(), d_y.begin(), d_z.begin(), saxpy(a));\n",
        "    auto end_gpu = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double> duration_gpu = end_gpu - start_gpu;\n",
        "    std::cout << \"Tempo de execução na GPU: \" << duration_gpu.count() << \" segundos\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -std=c++14 saxpy.cu -o saxpy"
      ],
      "metadata": {
        "id": "1LxLeegZIbmT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./saxpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqPjvH6sIeE6",
        "outputId": "34deed6c-a574-424d-9bf5-41c9fe685838"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de execução na CPU: 1.05724 segundos\n",
            "Tempo de execução na GPU: 0.00939285 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 2: Cálculo da Magnitude de um Vetor"
      ],
      "metadata": {
        "id": "d3zN9gQ0I3eF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile magnitude_compare.cu\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform_reduce.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "#include <cmath>\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <cstdlib>  // Para a função rand()\n",
        "\n",
        "// Functor para elevar ao quadrado\n",
        "struct square\n",
        "{\n",
        "    __host__ __device__\n",
        "    float operator()(const float& x) const {\n",
        "        return x * x;\n",
        "    }\n",
        "};\n",
        "\n",
        "// Função para calcular a magnitude na GPU\n",
        "float magnitude_gpu(thrust::device_vector<float>& v) {\n",
        "    float sum_of_squares = thrust::transform_reduce(v.begin(), v.end(), square(), 0.0f, thrust::plus<float>());\n",
        "    return std::sqrt(sum_of_squares);\n",
        "}\n",
        "\n",
        "// Função para calcular a magnitude na CPU\n",
        "float magnitude_cpu(const std::vector<float>& v) {\n",
        "    float sum_of_squares = 0.0f;\n",
        "    for (const auto& val : v) {\n",
        "        sum_of_squares += val * val;\n",
        "    }\n",
        "    return std::sqrt(sum_of_squares);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 1000000;  // Tamanho grande para comparação de performance\n",
        "    std::vector<float> h_v_cpu(N);\n",
        "\n",
        "    // Inicializar vetor com valores aleatórios\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        h_v_cpu[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    // Medir tempo para a CPU\n",
        "    auto start_cpu = std::chrono::high_resolution_clock::now();\n",
        "    float mag_cpu = magnitude_cpu(h_v_cpu);\n",
        "    auto end_cpu = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double> duration_cpu = end_cpu - start_cpu;\n",
        "    std::cout << \"Tempo de execução na CPU: \" << duration_cpu.count() << \" segundos\" << std::endl;\n",
        "    std::cout << \"Magnitude calculada na CPU: \" << mag_cpu << std::endl;\n",
        "\n",
        "    // Transferir para a GPU\n",
        "    thrust::host_vector<float> h_v = h_v_cpu;\n",
        "    thrust::device_vector<float> d_v = h_v;\n",
        "\n",
        "    // Medir tempo para a GPU\n",
        "    auto start_gpu = std::chrono::high_resolution_clock::now();\n",
        "    float mag_gpu = magnitude_gpu(d_v);\n",
        "    auto end_gpu = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double> duration_gpu = end_gpu - start_gpu;\n",
        "    std::cout << \"Tempo de execução na GPU: \" << duration_gpu.count() << \" segundos\" << std::endl;\n",
        "    std::cout << \"Magnitude calculada na GPU: \" << mag_gpu << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HnqmEDGIyaS",
        "outputId": "e7e7f7cf-6268-4ee1-b01e-6b9fc10cc4c1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting magnitude_compare.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -std=c++14 magnitude_compare.cu -o magnitude_compare"
      ],
      "metadata": {
        "id": "hLbrxbGYK25B"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./magnitude_compare"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3rZVFkzK49y",
        "outputId": "85c6b17f-359f-40d6-8375-116645918b3e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de execução na CPU: 0.0114911 segundos\n",
            "Magnitude calculada na CPU: 57344.2\n",
            "Tempo de execução na GPU: 0.000732848 segundos\n",
            "Magnitude calculada na GPU: 57297.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 3: Fusion Kernel - Cálculo da Variância"
      ],
      "metadata": {
        "id": "WCN8mVnVLxzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile variance_comparison.cu\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/transform_reduce.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <iostream>\n",
        "#include <chrono>\n",
        "#include <vector>\n",
        "#include <cmath>\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "\n",
        "// Functor para calcular (x_i - mean)^2 (Fusion Kernel)\n",
        "struct variance_op\n",
        "{\n",
        "    float mean;\n",
        "    variance_op(float mean_) : mean(mean_) {}\n",
        "\n",
        "    __host__ __device__\n",
        "    float operator()(const float& x) const {\n",
        "        float diff = x - mean;\n",
        "        return diff * diff;\n",
        "    }\n",
        "};\n",
        "\n",
        "// Cálculo de variância com Fusion Kernel\n",
        "float calculate_variance_gpu(const thrust::device_vector<float>& d_vec, float mean) {\n",
        "    return thrust::transform_reduce(d_vec.begin(), d_vec.end(), variance_op(mean), 0.0f, thrust::plus<float>()) / d_vec.size();\n",
        "}\n",
        "\n",
        "// Cálculo de variância separado (CPU)\n",
        "float calculate_variance_cpu(const std::vector<float>& vec) {\n",
        "    float sum = 0.0f;\n",
        "    for (float v : vec) {\n",
        "        sum += v;\n",
        "    }\n",
        "    float mean = sum / vec.size();\n",
        "\n",
        "    float variance_sum = 0.0f;\n",
        "    for (float v : vec) {\n",
        "        variance_sum += (v - mean) * (v - mean);\n",
        "    }\n",
        "\n",
        "    return variance_sum / vec.size();\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 1000000;  // Tamanho do vetor\n",
        "\n",
        "    // Inicializar vetor para CPU e GPU com valores aleatórios\n",
        "    std::vector<float> vec_cpu(N);\n",
        "    thrust::host_vector<float> h_vec(N);\n",
        "\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        float val = rand() % 100;\n",
        "        vec_cpu[i] = val;\n",
        "        h_vec[i] = val;\n",
        "    }\n",
        "\n",
        "    // Transferir os dados para a GPU\n",
        "    thrust::device_vector<float> d_vec = h_vec;\n",
        "\n",
        "    // ---------------------- GPU com Fusion Kernel ----------------------\n",
        "    auto start_gpu = std::chrono::steady_clock::now();\n",
        "\n",
        "    // Calcular a média na GPU\n",
        "    float mean_gpu = thrust::reduce(d_vec.begin(), d_vec.end(), 0.0f, thrust::plus<float>()) / N;\n",
        "\n",
        "    // Calcular a variância na GPU com Fusion Kernel\n",
        "    float variance_gpu = calculate_variance_gpu(d_vec, mean_gpu);\n",
        "\n",
        "    auto end_gpu = std::chrono::steady_clock::now();\n",
        "    std::chrono::duration<double> gpu_time = end_gpu - start_gpu;\n",
        "\n",
        "    // ---------------------- CPU Cálculo Tradicional ----------------------\n",
        "    auto start_cpu = std::chrono::steady_clock::now();\n",
        "\n",
        "    // Calcular a variância na CPU\n",
        "    float variance_cpu = calculate_variance_cpu(vec_cpu);\n",
        "\n",
        "    auto end_cpu = std::chrono::steady_clock::now();\n",
        "    std::chrono::duration<double> cpu_time = end_cpu - start_cpu;\n",
        "\n",
        "    // Exibir os resultados\n",
        "    std::cout << \"GPU Variância (Fusion Kernel): \" << variance_gpu << std::endl;\n",
        "    std::cout << \"GPU Tempo de execução: \" << gpu_time.count() << \" segundos\" << std::endl;\n",
        "\n",
        "    std::cout << \"CPU Variância (Cálculo Tradicional): \" << variance_cpu << std::endl;\n",
        "    std::cout << \"CPU Tempo de execução: \" << cpu_time.count() << \" segundos\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqU-pJS2K5yX",
        "outputId": "10f01698-4175-4092-e1d3-109ec9be8235"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting variance_comparison.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -std=c++14 variance_comparison.cu -o variance_comparison"
      ],
      "metadata": {
        "id": "t75lM1R8L2S-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./variance_comparison"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaqlFo_kL4Xp",
        "outputId": "fd113554-8686-4572-f763-038f6522f937"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Variância (Fusion Kernel): 832.932\n",
            "GPU Tempo de execução: 0.00101252 segundos\n",
            "CPU Variância (Cálculo Tradicional): 834.208\n",
            "CPU Tempo de execução: 0.0230668 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análise dos Resultados de Desempenho entre CPU e GPU\n",
        "\n",
        "Com os resultados obtidos para `n = 1.000.000`, podemos observar uma diferença significativa nos tempos de execução entre as implementações na **CPU** e na **GPU**. Vamos analisar cada parte separadamente e entender as causas das diferenças de tempo, o comportamento esperado para diferentes valores de `n`, e as reflexões sobre os valores calculados.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Parte 1: Saxpy**\n",
        "- **Tempo de execução na CPU**: 1.05724 segundos\n",
        "- **Tempo de execução na GPU**: 0.00939285 segundos\n",
        "\n",
        "**Análise:**\n",
        "A GPU apresentou um tempo de execução muito inferior ao da CPU, cerca de **100 vezes mais rápido**. Isso ocorre porque a GPU foi projetada para processar grandes quantidades de dados de forma paralela. No caso do Saxpy, cada elemento dos vetores pode ser processado independentemente, o que permite que a GPU calcule todos os elementos simultaneamente, aproveitando o paralelismo massivo. Em contrapartida, a CPU, mesmo sendo poderosa, processa os elementos de forma sequencial ou em pequenos lotes (dependendo dos núcleos disponíveis), o que gera um tempo maior para processar um volume de dados tão grande.\n",
        "\n",
        "**Comportamento com vetores menores:**\n",
        "Com vetores menores, a diferença entre os tempos de execução na CPU e GPU seria **muito menor**. Isso ocorre porque a GPU exige um **tempo de inicialização** e de **transferência de dados entre a CPU e GPU**, o que se torna uma fração mais significativa do tempo total quando o volume de dados é pequeno. Para pequenos valores de `n`, a CPU pode até ser mais rápida, pois não há necessidade de mover os dados para a GPU, o que elimina a sobrecarga de comunicação.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Parte 2: Cálculo da Magnitude**\n",
        "- **Tempo de execução na CPU**: 0.0114911 segundos\n",
        "- **Magnitude calculada na CPU**: 57344.2\n",
        "- **Tempo de execução na GPU**: 0.000732848 segundos\n",
        "- **Magnitude calculada na GPU**: 57297.8\n",
        "\n",
        "**Análise:**\n",
        "Novamente, a GPU apresentou um desempenho muito superior, sendo **mais de 10 vezes mais rápida** que a CPU. A GPU é muito eficiente ao realizar operações paralelas como a elevação ao quadrado de todos os elementos do vetor, enquanto a CPU precisa processar os elementos de forma sequencial.\n",
        "\n",
        "**Diferença nos valores de magnitude:**\n",
        "Os valores de magnitude calculados pela CPU e GPU são próximos, mas **não idênticos**. Essa diferença é causada por **pequenas imprecisões numéricas** que ocorrem devido à forma como os números de ponto flutuante são representados e processados em ambas as arquiteturas. A GPU pode utilizar otimizações de precisão, ou processar os valores em uma ordem ligeiramente diferente, o que resulta em essas variações, mas o erro é insignificante para a maioria dos propósitos práticos.\n",
        "\n",
        "**Comportamento com vetores menores:**\n",
        "Assim como no caso do Saxpy, para vetores menores, a diferença de tempo seria bem menor. A GPU teria que lidar com a sobrecarga de transferência de dados e inicialização, enquanto a CPU processaria o cálculo de magnitude localmente, sem necessidade de mover os dados entre dispositivos. Para `n` muito pequeno, a CPU pode até ser mais rápida.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Parte 3: Cálculo da Variância com Fusion Kernel**\n",
        "- **Variância calculada na GPU**: 832.932\n",
        "- **Tempo de execução na GPU**: 0.00101252 segundos\n",
        "- **Variância calculada na CPU**: 834.208\n",
        "- **Tempo de execução na CPU**: 0.0230668 segundos\n",
        "\n",
        "**Análise:**\n",
        "A diferença de desempenho aqui é **muito grande**, com a GPU sendo **mais de 20 vezes mais rápida**. Isso ocorre porque a técnica de **Fusion Kernel** permite que a GPU combine a transformação e a redução em um único passo, economizando tempo. Na CPU, o cálculo foi feito em duas etapas: primeiro calculando a média, depois somando as diferenças ao quadrado, o que aumenta o tempo total de execução. Na GPU, o **Fusion Kernel** elimina a necessidade de transferir os resultados intermediários entre as operações, resultando em um cálculo extremamente eficiente.\n",
        "\n",
        "**Diferença nos valores de variância:**\n",
        "Assim como na magnitude, as pequenas diferenças entre os valores de variância calculados na GPU e na CPU são resultado de **imprecisões numéricas**. A GPU pode processar os valores de ponto flutuante em uma ordem ligeiramente diferente da CPU, o que explica a variação. No entanto, o erro é insignificante para a maioria dos propósitos.\n",
        "\n",
        "**Comportamento com vetores menores:**\n",
        "Para vetores menores, o ganho de desempenho da GPU seria menos pronunciado, já que a CPU pode lidar eficientemente com pequenas quantidades de dados sem precisar mover informações para a GPU. Além disso, a inicialização da GPU e a transferência de dados podem representar uma parcela significativa do tempo total de execução para vetores pequenos. Nesse caso, o **Fusion Kernel** ainda seria mais eficiente na GPU em termos de processamento, mas a vantagem em termos de tempo de execução poderia diminuir.\n",
        "\n",
        "---\n",
        "\n",
        "### Reflexão sobre os Valores Calculados\n",
        "\n",
        "- **Comportamento de escalabilidade**: À medida que o tamanho de `n` aumenta, a GPU continua a se destacar em termos de tempo de execução, especialmente em tarefas altamente paralelizáveis, como o cálculo de variância e magnitude. No entanto, para valores pequenos de `n`, a sobrecarga de transferência de dados e inicialização da GPU pode diminuir sua vantagem, ou até torná-la mais lenta que a CPU para esses casos.\n",
        "\n",
        "### Conclusão\n",
        "\n",
        "Os resultados confirmam que a GPU é significativamente mais eficiente em termos de tempo para grandes volumes de dados devido à sua capacidade de processamento paralelo massivo. A técnica de **Fusion Kernel** maximiza essa eficiência ao combinar múltiplas operações em uma única etapa. No entanto, para vetores menores, a diferença de desempenho entre CPU e GPU é muito menor, devido à sobrecarga associada ao uso da GPU.\n",
        "\n",
        "Para `n` grande, a GPU é a melhor opção, enquanto para `n` pequeno, a CPU pode ser mais eficiente devido à menor complexidade de gerenciamento de dados."
      ],
      "metadata": {
        "id": "aZd_bT3cNq28"
      }
    }
  ]
}