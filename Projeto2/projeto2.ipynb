{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Projeto de Bioinformática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1: Contagem de Bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Códigos para a contagem total de A, T C e G nas bases de dados disponibilizadas.\n",
    "\n",
    "\n",
    "#### Implementação com OpenMP\n",
    "\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <fstream>\n",
    "#include <vector>\n",
    "#include <omp.h>\n",
    "#include <string>\n",
    "#include <filesystem>\n",
    "#include <cctype>  // Para std::toupper\n",
    "\n",
    "namespace fs = std::filesystem;\n",
    "\n",
    "// Função para contar bases em uma sequência\n",
    "void countBases(const std::string &sequence, int &countA, int &countT, int &countC, int &countG) {\n",
    "    #pragma omp parallel for reduction(+:countA, countT, countC, countG)\n",
    "    for (size_t i = 0; i < sequence.size(); ++i) {\n",
    "        char base = std::toupper(sequence[i]);  // Converte para maiúsculas\n",
    "        if (base == 'A') countA++;\n",
    "        else if (base == 'T') countT++;\n",
    "        else if (base == 'C') countC++;\n",
    "        else if (base == 'G') countG++;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Função para processar um arquivo e contar bases\n",
    "void processFile(const std::string &filename, int &countA, int &countT, int &countC, int &countG) {\n",
    "    std::ifstream file(filename);\n",
    "    if (!file.is_open()) {\n",
    "        std::cerr << \"Erro ao abrir o arquivo: \" << filename << \"\\n\";\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    std::string line, sequence;\n",
    "    while (std::getline(file, line)) {\n",
    "        if (line[0] != '>') {\n",
    "            sequence += line;  // Concatena todas as sequências do arquivo\n",
    "        }\n",
    "    }\n",
    "    file.close();\n",
    "    \n",
    "    countBases(sequence, countA, countT, countC, countG);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Diretório contendo os arquivos de dados\n",
    "    std::string directory = \"../database\";\n",
    "\n",
    "    int totalA = 0, totalT = 0, totalC = 0, totalG = 0;\n",
    "\n",
    "    // Itera sobre todos os arquivos na pasta `database` com extensão `.fa`\n",
    "    for (const auto &entry : fs::directory_iterator(directory)) {\n",
    "        if (entry.path().extension() == \".fa\") {\n",
    "            std::cout << \"Processando arquivo: \" << entry.path() << std::endl;\n",
    "            processFile(entry.path().string(), totalA, totalT, totalC, totalG);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Exibe o resultado final\n",
    "    std::cout << \"Total de bases A: \" << totalA << std::endl;\n",
    "    std::cout << \"Total de bases T: \" << totalT << std::endl;\n",
    "    std::cout << \"Total de bases C: \" << totalC << std::endl;\n",
    "    std::cout << \"Total de bases G: \" << totalG << std::endl;\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Implementação com MPI\n",
    "\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <fstream>\n",
    "#include <mpi.h>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "#include <filesystem>\n",
    "#include <cctype>  // Para std::toupper\n",
    "#include <algorithm>  // Para std::sort\n",
    "\n",
    "namespace fs = std::filesystem;\n",
    "\n",
    "// Função para contar bases em um arquivo com conversão para maiúsculas\n",
    "void count_bases_in_file(const std::string &filename, int &countA, int &countT, int &countC, int &countG) {\n",
    "    std::ifstream file(filename);\n",
    "    if (!file.is_open()) {\n",
    "        std::cerr << \"Erro ao abrir o arquivo: \" << filename << std::endl;\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    std::string line;\n",
    "    while (std::getline(file, line)) {\n",
    "        if (line.empty() || line[0] == '>') continue;  // Ignora linhas de cabeçalho ou vazias\n",
    "        for (char base : line) {\n",
    "            base = std::toupper(base);  // Converte para maiúsculas\n",
    "            if (base == 'A') countA++;\n",
    "            else if (base == 'T') countT++;\n",
    "            else if (base == 'C') countC++;\n",
    "            else if (base == 'G') countG++;\n",
    "        }\n",
    "    }\n",
    "    file.close();\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "    // Diretório contendo os arquivos de dados\n",
    "    std::string directory = \"../database\";\n",
    "    std::vector<std::string> files;\n",
    "\n",
    "    // Todos os processos obtêm a lista de arquivos e a ordenam\n",
    "    for (const auto &entry : fs::directory_iterator(directory)) {\n",
    "        if (entry.path().extension() == \".fa\") {\n",
    "            files.push_back(entry.path().string());\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Ordena a lista de arquivos para garantir a mesma ordem em todos os processos\n",
    "    std::sort(files.begin(), files.end());\n",
    "\n",
    "    int num_files = files.size();\n",
    "\n",
    "    // Calcula os índices de início e fim para cada processo\n",
    "    int files_per_process = num_files / size;\n",
    "    int remainder = num_files % size;\n",
    "    int start_idx = rank * files_per_process + std::min(rank, remainder);\n",
    "    int end_idx = start_idx + files_per_process + (rank < remainder ? 1 : 0);\n",
    "\n",
    "    // Para depuração: exibe quais arquivos cada processo está processando\n",
    "    std::cout << \"Processo \" << rank << \" processando arquivos de índice \" << start_idx << \" a \" << end_idx - 1 << std::endl;\n",
    "\n",
    "    // Contagem de bases locais para cada processo\n",
    "    int local_countA = 0, local_countT = 0, local_countC = 0, local_countG = 0;\n",
    "\n",
    "    for (int i = start_idx; i < end_idx; ++i) {\n",
    "        std::cout << \"Processo \" << rank << \" processando arquivo: \" << files[i] << std::endl;\n",
    "        count_bases_in_file(files[i], local_countA, local_countT, local_countC, local_countG);\n",
    "    }\n",
    "\n",
    "    // Reduz as contagens locais em uma soma global no processo 0\n",
    "    int global_countA = 0, global_countT = 0, global_countC = 0, global_countG = 0;\n",
    "    MPI_Reduce(&local_countA, &global_countA, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    MPI_Reduce(&local_countT, &global_countT, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    MPI_Reduce(&local_countC, &global_countC, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    MPI_Reduce(&local_countG, &global_countG, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    // Apenas o processo 0 exibe o resultado final\n",
    "    if (rank == 0) {\n",
    "        std::cout << \"Total de bases A: \" << global_countA << std::endl;\n",
    "        std::cout << \"Total de bases T: \" << global_countT << std::endl;\n",
    "        std::cout << \"Total de bases C: \" << global_countC << std::endl;\n",
    "        std::cout << \"Total de bases G: \" << global_countG << std::endl;\n",
    "    }\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Implementação híbrida com OpenMP e MPI\n",
    "\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <fstream>\n",
    "#include <mpi.h>\n",
    "#include <omp.h>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "#include <filesystem>\n",
    "#include <chrono>\n",
    "\n",
    "namespace fs = std::filesystem;\n",
    "\n",
    "// Função para contar bases em uma sequência usando OpenMP\n",
    "void count_bases_in_sequence(const std::string &sequence, int &countA, int &countT, int &countC, int &countG) {\n",
    "    #pragma omp parallel for reduction(+:countA, countT, countC, countG)\n",
    "    for (size_t i = 0; i < sequence.size(); ++i) {\n",
    "        char base = std::toupper(sequence[i]);\n",
    "        if (base == 'A') countA++;\n",
    "        else if (base == 'T') countT++;\n",
    "        else if (base == 'C') countC++;\n",
    "        else if (base == 'G') countG++;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Função para contar bases em um arquivo\n",
    "void count_bases_in_file(const std::string &filename, int &countA, int &countT, int &countC, int &countG) {\n",
    "    std::ifstream file(filename);\n",
    "    if (!file.is_open()) {\n",
    "        std::cerr << \"Erro ao abrir o arquivo: \" << filename << std::endl;\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    std::string line, sequence;\n",
    "    while (std::getline(file, line)) {\n",
    "        if (line[0] != '>') {\n",
    "            sequence += line;\n",
    "        }\n",
    "    }\n",
    "    file.close();\n",
    "    count_bases_in_sequence(sequence, countA, countT, countC, countG);\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "    std::string directory = \"../database\";\n",
    "    std::vector<std::string> files;\n",
    "\n",
    "    // O processo 0 coleta a lista de arquivos e distribui entre os processos\n",
    "    if (rank == 0) {\n",
    "        for (const auto &entry : fs::directory_iterator(directory)) {\n",
    "            if (entry.path().extension() == \".fa\") {\n",
    "                files.push_back(entry.path().string());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Broadcast do número de arquivos para todos os processos\n",
    "    int num_files = files.size();\n",
    "    MPI_Bcast(&num_files, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    // Broadcast da lista de arquivos para todos os processos\n",
    "    if (rank != 0) {\n",
    "        files.resize(num_files);\n",
    "    }\n",
    "    for (int i = 0; i < num_files; i++) {\n",
    "        int length = (rank == 0) ? files[i].size() : 0;\n",
    "        MPI_Bcast(&length, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "        if (rank != 0) {\n",
    "            files[i].resize(length);\n",
    "        }\n",
    "        MPI_Bcast(&files[i][0], length, MPI_CHAR, 0, MPI_COMM_WORLD);\n",
    "    }\n",
    "\n",
    "    auto start = std::chrono::high_resolution_clock::now();\n",
    "\n",
    "    // Contagem de bases locais para cada processo\n",
    "    int local_countA = 0, local_countT = 0, local_countC = 0, local_countG = 0;\n",
    "\n",
    "    // Processa os arquivos divididos entre os processos com OpenMP\n",
    "    for (int i = rank; i < num_files; i += size) {\n",
    "        count_bases_in_file(files[i], local_countA, local_countT, local_countC, local_countG);\n",
    "    }\n",
    "\n",
    "    // Reduz as contagens locais em uma soma global no processo 0\n",
    "    int global_countA, global_countT, global_countC, global_countG;\n",
    "    MPI_Reduce(&local_countA, &global_countA, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    MPI_Reduce(&local_countT, &global_countT, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    MPI_Reduce(&local_countC, &global_countC, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    MPI_Reduce(&local_countG, &global_countG, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "    std::chrono::duration<double> elapsed = end - start;\n",
    "\n",
    "    // Apenas o processo 0 exibe o resultado final\n",
    "    if (rank == 0) {\n",
    "        std::cout << \"Total de bases A: \" << global_countA << std::endl;\n",
    "        std::cout << \"Total de bases T: \" << global_countT << std::endl;\n",
    "        std::cout << \"Total de bases C: \" << global_countC << std::endl;\n",
    "        std::cout << \"Total de bases G: \" << global_countG << std::endl;\n",
    "        std::cout << \"Tempo total de execução: \" << elapsed.count() << \" segundos\" << std::endl;\n",
    "    }\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Resultados obtidos\n",
    "\n",
    "#### OpenMP\n",
    "\n",
    "- Total de bases A: 763517118\n",
    "- Total de bases T: 764606176\n",
    "- Total de bases C: 511685713\n",
    "- Total de bases G: 511971484\n",
    "- Tempo total de execução (OpenMP): 9.65299 segundos\n",
    "\n",
    "#### MPI\n",
    "\n",
    "- Total de bases A: 763517118\n",
    "- Total de bases T: 764606176\n",
    "- Total de bases C: 511685713\n",
    "- Total de bases G: 511971484\n",
    "- Tempo total de execução (MPI): 11.1374 segundos\n",
    "\n",
    "#### OpenMP + MPI\n",
    "\n",
    "- Total de bases A: 763517118\n",
    "- Total de bases T: 764606176\n",
    "- Total de bases C: 511685713\n",
    "- Total de bases G: 511971484\n",
    "- Tempo total de execução (Híbrido OpenMP + MPI): 5.75119 segundos\n",
    "\n",
    "---\n",
    "\n",
    "### Análise das Implementações: Exercício 1\n",
    "\n",
    "O objetivo do exercício foi realizar a contagem de bases nucleotídicas (A, T, C e G) em um conjunto de arquivos FASTA que representam sequências cromossômicas. Três abordagens distintas foram utilizadas: OpenMP, MPI, e uma versão híbrida que combina ambas as técnicas para maximizar a eficiência.\n",
    "\n",
    "#### 1. Implementação com OpenMP\n",
    "A primeira implementação utilizou **OpenMP** para realizar paralelismo local em um único processador com múltiplas threads. Nesta abordagem:\n",
    "   - **Divisão de Trabalho**: Cada thread processa um arquivo FASTA, permitindo o processamento simultâneo de diferentes arquivos na mesma máquina.\n",
    "   - **Preprocessamento**: Todas as sequências foram convertidas para letras maiúsculas para garantir uniformidade na contagem, caso existissem variações de formatação.\n",
    "   - **Desempenho**: Esta abordagem foi capaz de reduzir o tempo de execução comparado a um processamento sequencial, mas limitada pela quantidade de núcleos disponíveis em um único processador.\n",
    "\n",
    "   - **Tempo Total de Execução**: 9.65299 segundos\n",
    "\n",
    "#### 2. Implementação com MPI\n",
    "A segunda abordagem utilizou **MPI** para dividir a carga de trabalho entre diferentes processadores:\n",
    "   - **Distribuição de Arquivos**: Cada processo MPI recebeu um conjunto de arquivos para processamento. Isso permitiu que a carga fosse distribuída entre várias máquinas, reduzindo o tempo de execução em um sistema com múltiplos nós.\n",
    "   - **Paralelismo Entre Processadores**: Ao invés de threads locais, cada processo MPI operava independentemente em uma seção dos arquivos, o que permite processamento paralelo em clusters de máquinas.\n",
    "   - **Desempenho**: O uso de MPI aumentou a eficiência da execução em um ambiente de cluster, mas o tempo de comunicação entre processos limitou um pouco a melhoria de desempenho em comparação com o OpenMP em um único nó.\n",
    "\n",
    "   - **Tempo Total de Execução**: 11.1374 segundos\n",
    "\n",
    "#### 3. Implementação Híbrida (OpenMP + MPI)\n",
    "A terceira e mais eficiente abordagem combinou OpenMP e MPI, tirando proveito do paralelismo em diferentes níveis:\n",
    "   - **Divisão de Trabalho em Níveis**: A carga de trabalho foi distribuída entre múltiplos processos MPI, e cada processo utilizou threads OpenMP para processar os arquivos em paralelo localmente.\n",
    "   - **Eficiência e Redução de Tempo**: Essa abordagem combinou o melhor das duas técnicas. Cada nó do cluster processava múltiplos arquivos em paralelo, e o uso de MPI permitiu a divisão da carga de trabalho entre nós. Com isso, houve uma diminuição significativa do tempo total de execução.\n",
    "   - **Desempenho**: O uso da implementação híbrida trouxe o menor tempo de execução, combinando os benefícios de ambas as técnicas para aproveitar ao máximo os recursos computacionais disponíveis.\n",
    "\n",
    "   - **Tempo Total de Execução**: 5.75119 segundos\n",
    "\n",
    "---\n",
    "\n",
    "### Comparação dos Tempos de Execução e Eficiência\n",
    "\n",
    "| Implementação      | Tempo Total (segundos) | Observações                                                                                   |\n",
    "|--------------------|------------------------|-----------------------------------------------------------------------------------------------|\n",
    "| OpenMP               | 9.65299              | Paralelismo local com threads, limitado pela quantidade de núcleos no processador.             |\n",
    "| MPI                  | 11.1374              | Distribuição entre processos MPI, limitado pela comunicação entre processos.                   |\n",
    "| Híbrida (OpenMP+MPI) | 5.75119              | Paralelismo em múltiplos níveis (processos MPI + threads OpenMP), resultando no menor tempo.   |\n",
    "\n",
    "A análise dos tempos de execução indica que a abordagem híbrida obteve o melhor desempenho, pois conseguiu combinar o processamento distribuído do MPI com o paralelismo local do OpenMP. Isso resultou em um uso mais eficiente dos recursos computacionais, especialmente em um ambiente com múltiplos nós e núcleos.\n",
    "\n",
    "### Considerações Finais\n",
    "\n",
    "As três abordagens mostraram-se eficazes na contagem de bases nucleotídicas, e a escolha entre elas depende do ambiente de execução. Em um sistema com um único processador, o OpenMP seria suficiente. No entanto, para grandes volumes de dados em um ambiente de cluster, a abordagem híbrida demonstrou ser a mais eficiente. Essa estratégia também é escalável, permitindo um processamento mais rápido em infraestruturas maiores, o que é fundamental para análises de bioinformática em larga escala. \n",
    "\n",
    "Além disso, o preprocessamento de conversão para letras maiúsculas garantiu consistência nos dados e precisão na contagem, eliminando potenciais variações de formato dos arquivos originais.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
