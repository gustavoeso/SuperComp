{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Projeto de Bioinformática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1: Contagem de Bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Códigos para a contagem total de A, T C e G nas bases de dados disponibilizadas.\n",
    "\n",
    "\n",
    "#### Implementação com OpenMP\n",
    "\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <fstream>\n",
    "#include <vector>\n",
    "#include <omp.h>\n",
    "#include <string>\n",
    "#include <filesystem>\n",
    "#include <cctype>  // Para std::toupper\n",
    "\n",
    "namespace fs = std::filesystem;\n",
    "\n",
    "// Função para contar bases em uma sequência\n",
    "void countBases(const std::string &sequence, int &countA, int &countT, int &countC, int &countG) {\n",
    "    #pragma omp parallel for reduction(+:countA, countT, countC, countG)\n",
    "    for (size_t i = 0; i < sequence.size(); ++i) {\n",
    "        char base = std::toupper(sequence[i]);  // Converte para maiúsculas\n",
    "        if (base == 'A') countA++;\n",
    "        else if (base == 'T') countT++;\n",
    "        else if (base == 'C') countC++;\n",
    "        else if (base == 'G') countG++;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Função para processar um arquivo e contar bases\n",
    "void processFile(const std::string &filename, int &countA, int &countT, int &countC, int &countG) {\n",
    "    std::ifstream file(filename);\n",
    "    if (!file.is_open()) {\n",
    "        std::cerr << \"Erro ao abrir o arquivo: \" << filename << \"\\n\";\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    std::string line, sequence;\n",
    "    while (std::getline(file, line)) {\n",
    "        if (line[0] != '>') {\n",
    "            sequence += line;  // Concatena todas as sequências do arquivo\n",
    "        }\n",
    "    }\n",
    "    file.close();\n",
    "    \n",
    "    countBases(sequence, countA, countT, countC, countG);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Diretório contendo os arquivos de dados\n",
    "    std::string directory = \"../database\";\n",
    "\n",
    "    int totalA = 0, totalT = 0, totalC = 0, totalG = 0;\n",
    "\n",
    "    // Itera sobre todos os arquivos na pasta `database` com extensão `.fa`\n",
    "    for (const auto &entry : fs::directory_iterator(directory)) {\n",
    "        if (entry.path().extension() == \".fa\") {\n",
    "            std::cout << \"Processando arquivo: \" << entry.path() << std::endl;\n",
    "            processFile(entry.path().string(), totalA, totalT, totalC, totalG);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Exibe o resultado final\n",
    "    std::cout << \"Total de bases A: \" << totalA << std::endl;\n",
    "    std::cout << \"Total de bases T: \" << totalT << std::endl;\n",
    "    std::cout << \"Total de bases C: \" << totalC << std::endl;\n",
    "    std::cout << \"Total de bases G: \" << totalG << std::endl;\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Implementação com MPI\n",
    "\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <fstream>\n",
    "#include <mpi.h>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "#include <filesystem>\n",
    "#include <cctype>  // Para std::toupper\n",
    "#include <algorithm>  // Para std::sort\n",
    "\n",
    "namespace fs = std::filesystem;\n",
    "\n",
    "// Função para contar bases em um arquivo com conversão para maiúsculas\n",
    "void count_bases_in_file(const std::string &filename, int &countA, int &countT, int &countC, int &countG) {\n",
    "    std::ifstream file(filename);\n",
    "    if (!file.is_open()) {\n",
    "        std::cerr << \"Erro ao abrir o arquivo: \" << filename << std::endl;\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    std::string line;\n",
    "    while (std::getline(file, line)) {\n",
    "        if (line.empty() || line[0] == '>') continue;  // Ignora linhas de cabeçalho ou vazias\n",
    "        for (char base : line) {\n",
    "            base = std::toupper(base);  // Converte para maiúsculas\n",
    "            if (base == 'A') countA++;\n",
    "            else if (base == 'T') countT++;\n",
    "            else if (base == 'C') countC++;\n",
    "            else if (base == 'G') countG++;\n",
    "        }\n",
    "    }\n",
    "    file.close();\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "    // Diretório contendo os arquivos de dados\n",
    "    std::string directory = \"../database\";\n",
    "    std::vector<std::string> files;\n",
    "\n",
    "    // Todos os processos obtêm a lista de arquivos e a ordenam\n",
    "    for (const auto &entry : fs::directory_iterator(directory)) {\n",
    "        if (entry.path().extension() == \".fa\") {\n",
    "            files.push_back(entry.path().string());\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Ordena a lista de arquivos para garantir a mesma ordem em todos os processos\n",
    "    std::sort(files.begin(), files.end());\n",
    "\n",
    "    int num_files = files.size();\n",
    "\n",
    "    // Calcula os índices de início e fim para cada processo\n",
    "    int files_per_process = num_files / size;\n",
    "    int remainder = num_files % size;\n",
    "    int start_idx = rank * files_per_process + std::min(rank, remainder);\n",
    "    int end_idx = start_idx + files_per_process + (rank < remainder ? 1 : 0);\n",
    "\n",
    "    // Para depuração: exibe quais arquivos cada processo está processando\n",
    "    std::cout << \"Processo \" << rank << \" processando arquivos de índice \" << start_idx << \" a \" << end_idx - 1 << std::endl;\n",
    "\n",
    "    // Contagem de bases locais para cada processo\n",
    "    int local_countA = 0, local_countT = 0, local_countC = 0, local_countG = 0;\n",
    "\n",
    "    for (int i = start_idx; i < end_idx; ++i) {\n",
    "        std::cout << \"Processo \" << rank << \" processando arquivo: \" << files[i] << std::endl;\n",
    "        count_bases_in_file(files[i], local_countA, local_countT, local_countC, local_countG);\n",
    "    }\n",
    "\n",
    "    // Reduz as contagens locais em uma soma global no processo 0\n",
    "    int global_countA = 0, global_countT = 0, global_countC = 0, global_countG = 0;\n",
    "    MPI_Reduce(&local_countA, &global_countA, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    MPI_Reduce(&local_countT, &global_countT, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    MPI_Reduce(&local_countC, &global_countC, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    MPI_Reduce(&local_countG, &global_countG, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    // Apenas o processo 0 exibe o resultado final\n",
    "    if (rank == 0) {\n",
    "        std::cout << \"Total de bases A: \" << global_countA << std::endl;\n",
    "        std::cout << \"Total de bases T: \" << global_countT << std::endl;\n",
    "        std::cout << \"Total de bases C: \" << global_countC << std::endl;\n",
    "        std::cout << \"Total de bases G: \" << global_countG << std::endl;\n",
    "    }\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Implementação híbrida com OpenMP e MPI\n",
    "\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <fstream>\n",
    "#include <mpi.h>\n",
    "#include <omp.h>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "#include <filesystem>\n",
    "#include <chrono>\n",
    "\n",
    "namespace fs = std::filesystem;\n",
    "\n",
    "// Função para contar bases em uma sequência usando OpenMP\n",
    "void count_bases_in_sequence(const std::string &sequence, int &countA, int &countT, int &countC, int &countG) {\n",
    "    #pragma omp parallel for reduction(+:countA, countT, countC, countG)\n",
    "    for (size_t i = 0; i < sequence.size(); ++i) {\n",
    "        char base = std::toupper(sequence[i]);\n",
    "        if (base == 'A') countA++;\n",
    "        else if (base == 'T') countT++;\n",
    "        else if (base == 'C') countC++;\n",
    "        else if (base == 'G') countG++;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Função para contar bases em um arquivo\n",
    "void count_bases_in_file(const std::string &filename, int &countA, int &countT, int &countC, int &countG) {\n",
    "    std::ifstream file(filename);\n",
    "    if (!file.is_open()) {\n",
    "        std::cerr << \"Erro ao abrir o arquivo: \" << filename << std::endl;\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    std::string line, sequence;\n",
    "    while (std::getline(file, line)) {\n",
    "        if (line[0] != '>') {\n",
    "            sequence += line;\n",
    "        }\n",
    "    }\n",
    "    file.close();\n",
    "    count_bases_in_sequence(sequence, countA, countT, countC, countG);\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "    std::string directory = \"../database\";\n",
    "    std::vector<std::string> files;\n",
    "\n",
    "    // O processo 0 coleta a lista de arquivos e distribui entre os processos\n",
    "    if (rank == 0) {\n",
    "        for (const auto &entry : fs::directory_iterator(directory)) {\n",
    "            if (entry.path().extension() == \".fa\") {\n",
    "                files.push_back(entry.path().string());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Broadcast do número de arquivos para todos os processos\n",
    "    int num_files = files.size();\n",
    "    MPI_Bcast(&num_files, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    // Broadcast da lista de arquivos para todos os processos\n",
    "    if (rank != 0) {\n",
    "        files.resize(num_files);\n",
    "    }\n",
    "    for (int i = 0; i < num_files; i++) {\n",
    "        int length = (rank == 0) ? files[i].size() : 0;\n",
    "        MPI_Bcast(&length, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "        if (rank != 0) {\n",
    "            files[i].resize(length);\n",
    "        }\n",
    "        MPI_Bcast(&files[i][0], length, MPI_CHAR, 0, MPI_COMM_WORLD);\n",
    "    }\n",
    "\n",
    "    auto start = std::chrono::high_resolution_clock::now();\n",
    "\n",
    "    // Contagem de bases locais para cada processo\n",
    "    int local_countA = 0, local_countT = 0, local_countC = 0, local_countG = 0;\n",
    "\n",
    "    // Processa os arquivos divididos entre os processos com OpenMP\n",
    "    for (int i = rank; i < num_files; i += size) {\n",
    "        count_bases_in_file(files[i], local_countA, local_countT, local_countC, local_countG);\n",
    "    }\n",
    "\n",
    "    // Reduz as contagens locais em uma soma global no processo 0\n",
    "    int global_countA, global_countT, global_countC, global_countG;\n",
    "    MPI_Reduce(&local_countA, &global_countA, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    MPI_Reduce(&local_countT, &global_countT, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    MPI_Reduce(&local_countC, &global_countC, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    MPI_Reduce(&local_countG, &global_countG, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "    std::chrono::duration<double> elapsed = end - start;\n",
    "\n",
    "    // Apenas o processo 0 exibe o resultado final\n",
    "    if (rank == 0) {\n",
    "        std::cout << \"Total de bases A: \" << global_countA << std::endl;\n",
    "        std::cout << \"Total de bases T: \" << global_countT << std::endl;\n",
    "        std::cout << \"Total de bases C: \" << global_countC << std::endl;\n",
    "        std::cout << \"Total de bases G: \" << global_countG << std::endl;\n",
    "        std::cout << \"Tempo total de execução: \" << elapsed.count() << \" segundos\" << std::endl;\n",
    "    }\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Resultados obtidos\n",
    "\n",
    "#### OpenMP\n",
    "\n",
    "- Total de bases A: 763517118\n",
    "- Total de bases T: 764606176\n",
    "- Total de bases C: 511685713\n",
    "- Total de bases G: 511971484\n",
    "- Tempo total de execução (OpenMP): 9.65299 segundos\n",
    "\n",
    "#### MPI\n",
    "\n",
    "- Total de bases A: 763517118\n",
    "- Total de bases T: 764606176\n",
    "- Total de bases C: 511685713\n",
    "- Total de bases G: 511971484\n",
    "- Tempo total de execução (MPI): 11.1374 segundos\n",
    "\n",
    "#### OpenMP + MPI\n",
    "\n",
    "- Total de bases A: 763517118\n",
    "- Total de bases T: 764606176\n",
    "- Total de bases C: 511685713\n",
    "- Total de bases G: 511971484\n",
    "- Tempo total de execução (Híbrido OpenMP + MPI): 5.75119 segundos\n",
    "\n",
    "---\n",
    "\n",
    "### Análise das Implementações: Exercício 1\n",
    "\n",
    "O objetivo do exercício foi realizar a contagem de bases nucleotídicas (A, T, C e G) em um conjunto de arquivos FASTA que representam sequências cromossômicas. Três abordagens distintas foram utilizadas: OpenMP, MPI, e uma versão híbrida que combina ambas as técnicas para maximizar a eficiência.\n",
    "\n",
    "#### 1. Implementação com OpenMP\n",
    "A primeira implementação utilizou **OpenMP** para realizar paralelismo local em um único processador com múltiplas threads. Nesta abordagem:\n",
    "   - **Divisão de Trabalho**: Cada thread processa um arquivo FASTA, permitindo o processamento simultâneo de diferentes arquivos na mesma máquina.\n",
    "   - **Preprocessamento**: Todas as sequências foram convertidas para letras maiúsculas para garantir uniformidade na contagem, caso existissem variações de formatação.\n",
    "   - **Desempenho**: Esta abordagem foi capaz de reduzir o tempo de execução comparado a um processamento sequencial, mas limitada pela quantidade de núcleos disponíveis em um único processador.\n",
    "\n",
    "   - **Tempo Total de Execução**: 9.65299 segundos\n",
    "\n",
    "#### 2. Implementação com MPI\n",
    "A segunda abordagem utilizou **MPI** para dividir a carga de trabalho entre diferentes processadores:\n",
    "   - **Distribuição de Arquivos**: Cada processo MPI recebeu um conjunto de arquivos para processamento. Isso permitiu que a carga fosse distribuída entre várias máquinas, reduzindo o tempo de execução em um sistema com múltiplos nós.\n",
    "   - **Paralelismo Entre Processadores**: Ao invés de threads locais, cada processo MPI operava independentemente em uma seção dos arquivos, o que permite processamento paralelo em clusters de máquinas.\n",
    "   - **Desempenho**: O uso de MPI aumentou a eficiência da execução em um ambiente de cluster, mas o tempo de comunicação entre processos limitou um pouco a melhoria de desempenho em comparação com o OpenMP em um único nó.\n",
    "\n",
    "   - **Tempo Total de Execução**: 11.1374 segundos\n",
    "\n",
    "#### 3. Implementação Híbrida (OpenMP + MPI)\n",
    "A terceira e mais eficiente abordagem combinou OpenMP e MPI, tirando proveito do paralelismo em diferentes níveis:\n",
    "   - **Divisão de Trabalho em Níveis**: A carga de trabalho foi distribuída entre múltiplos processos MPI, e cada processo utilizou threads OpenMP para processar os arquivos em paralelo localmente.\n",
    "   - **Eficiência e Redução de Tempo**: Essa abordagem combinou o melhor das duas técnicas. Cada nó do cluster processava múltiplos arquivos em paralelo, e o uso de MPI permitiu a divisão da carga de trabalho entre nós. Com isso, houve uma diminuição significativa do tempo total de execução.\n",
    "   - **Desempenho**: O uso da implementação híbrida trouxe o menor tempo de execução, combinando os benefícios de ambas as técnicas para aproveitar ao máximo os recursos computacionais disponíveis.\n",
    "\n",
    "   - **Tempo Total de Execução**: 5.75119 segundos\n",
    "\n",
    "---\n",
    "\n",
    "### Comparação dos Tempos de Execução e Eficiência\n",
    "\n",
    "| Implementação      | Tempo Total (segundos) | Observações                                                                                   |\n",
    "|--------------------|------------------------|-----------------------------------------------------------------------------------------------|\n",
    "| OpenMP               | 9.65299              | Paralelismo local com threads, limitado pela quantidade de núcleos no processador.             |\n",
    "| MPI                  | 11.1374              | Distribuição entre processos MPI, limitado pela comunicação entre processos.                   |\n",
    "| Híbrida (OpenMP+MPI) | 5.75119              | Paralelismo em múltiplos níveis (processos MPI + threads OpenMP), resultando no menor tempo.   |\n",
    "\n",
    "A análise dos tempos de execução indica que a abordagem híbrida obteve o melhor desempenho, pois conseguiu combinar o processamento distribuído do MPI com o paralelismo local do OpenMP. Isso resultou em um uso mais eficiente dos recursos computacionais, especialmente em um ambiente com múltiplos nós e núcleos.\n",
    "\n",
    "### Considerações Finais\n",
    "\n",
    "As três abordagens mostraram-se eficazes na contagem de bases nucleotídicas, e a escolha entre elas depende do ambiente de execução. Em um sistema com um único processador, o OpenMP seria suficiente. No entanto, para grandes volumes de dados em um ambiente de cluster, a abordagem híbrida demonstrou ser a mais eficiente. Essa estratégia também é escalável, permitindo um processamento mais rápido em infraestruturas maiores, o que é fundamental para análises de bioinformática em larga escala. \n",
    "\n",
    "Além disso, o preprocessamento de conversão para letras maiúsculas garantiu consistência nos dados e precisão na contagem, eliminando potenciais variações de formato dos arquivos originais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2: Transcrição de DNA em RNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código para transição de DNA para RNA\n",
    "\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <fstream>\n",
    "#include <mpi.h>\n",
    "#include <omp.h>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "#include <filesystem>\n",
    "\n",
    "// Função para processar um arquivo e converter DNA para RNA\n",
    "std::string processarArquivo(const std::string &filename) {\n",
    "    std::ifstream file(filename);\n",
    "    if (!file.is_open()) {\n",
    "        std::cerr << \"Erro ao abrir o arquivo: \" << filename << \"\\n\";\n",
    "        return \"\";\n",
    "    }\n",
    "\n",
    "    std::string line, sequenciaRNA;\n",
    "    while (std::getline(file, line)) {\n",
    "        if (line[0] != '>') {  // Ignora cabeçalhos\n",
    "            for (char base : line) {\n",
    "                sequenciaRNA += (base == 'T') ? 'U' : toupper(base);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    file.close();\n",
    "    return sequenciaRNA;\n",
    "}\n",
    "\n",
    "// Função para salvar cada RNA gerado em um arquivo individual na pasta \"output\"\n",
    "void salvarRNA(const std::string &rnaSequencia, const std::string &filename) {\n",
    "    std::filesystem::create_directory(\"output\");  // Cria a pasta 'output' se não existir\n",
    "    std::string outputFilename = \"output/\" + filename + \".rna.fa\";\n",
    "\n",
    "    std::ofstream arquivoSaida(outputFilename);\n",
    "    if (arquivoSaida.is_open()) {\n",
    "        arquivoSaida << rnaSequencia << \"\\n\";\n",
    "        arquivoSaida.close();\n",
    "        std::cout << \"Arquivo RNA salvo em: \" << outputFilename << std::endl;\n",
    "    } else {\n",
    "        std::cerr << \"Erro ao abrir o arquivo para salvar o RNA: \" << outputFilename << \"\\n\";\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "    const std::string directory = \"../database\";\n",
    "    std::vector<std::string> files;\n",
    "\n",
    "    if (rank == 0) {\n",
    "        for (const auto &entry : std::filesystem::directory_iterator(directory)) {\n",
    "            if (entry.path().extension() == \".fa\") {\n",
    "                files.push_back(entry.path().string());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    int num_files = files.size();\n",
    "    MPI_Bcast(&num_files, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "    if (rank != 0) files.resize(num_files);\n",
    "\n",
    "    for (int i = 0; i < num_files; i++) {\n",
    "        int length = (rank == 0) ? files[i].size() : 0;\n",
    "        MPI_Bcast(&length, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "        if (rank != 0) files[i].resize(length);\n",
    "        MPI_Bcast(&files[i][0], length, MPI_CHAR, 0, MPI_COMM_WORLD);\n",
    "    }\n",
    "\n",
    "    double start_time = MPI_Wtime();\n",
    "\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        #pragma omp for\n",
    "        for (int i = rank; i < num_files; i += size) {\n",
    "            std::string rna = processarArquivo(files[i]);\n",
    "            std::string filename = std::filesystem::path(files[i]).stem();\n",
    "            salvarRNA(rna, filename);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (rank == 0) {\n",
    "        double end_time = MPI_Wtime();\n",
    "        std::cout << \"Tempo total de execução (Híbrido MPI + OpenMP): \" << (end_time - start_time) << \" segundos\\n\";\n",
    "    }\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "O código desenvolvido para o *Exercício 2 - Híbrido (MPI + OpenMP)* utiliza uma abordagem híbrida de paralelização para maximizar a eficiência e reduzir o tempo de processamento na conversão de sequências de DNA para RNA. A solução adota uma combinação das bibliotecas MPI e OpenMP para dividir a tarefa de leitura e processamento dos arquivos em múltiplos processos e threads, garantindo que o tempo de execução seja otimizado, mesmo com um número elevado de arquivos.\n",
    "\n",
    "### Descrição Técnica\n",
    "1. **Divisão com MPI**: O código começa distribuindo os arquivos de entrada entre diferentes processos MPI. Cada processo é responsável por processar um subconjunto de arquivos. A divisão é feita de forma balanceada, de modo que cada processo MPI recebe um número equivalente de arquivos, reduzindo a carga de trabalho total.\n",
    "\n",
    "2. **Conversão de DNA para RNA com OpenMP**: Dentro de cada processo MPI, utilizamos o OpenMP para paralelizar o processamento de cada arquivo, permitindo que múltiplas threads trabalhem simultaneamente na leitura e transformação das bases. A conversão substitui a base “T” por “U”, gerando a sequência de RNA correspondente para cada arquivo de DNA.\n",
    "\n",
    "3. **Armazenamento dos Resultados em Arquivos Separados**: Cada arquivo `.fa` de entrada gera um arquivo correspondente de saída em uma pasta chamada `output/`, onde o RNA processado é salvo. A escolha de gerar arquivos de saída separados foi feita para evitar problemas de sobrescrita e facilitar a organização dos resultados.\n",
    "\n",
    "4. **Medição do Tempo de Execução**: O tempo total de execução do programa é calculado e exibido no processo principal. Essa métrica é útil para analisar o desempenho do código, possibilitando uma comparação com outras abordagens.\n",
    "\n",
    "### Reflexão sobre a Implementação\n",
    "A abordagem híbrida utilizada permite explorar o máximo potencial do ambiente de execução, combinando a distribuição de tarefas de MPI e a execução paralela de OpenMP. A estratégia reduz consideravelmente o tempo de processamento, especialmente em um cenário com múltiplos arquivos. A separação dos arquivos de saída facilita a organização dos resultados e contribui para uma solução escalável, adaptável a grandes conjuntos de dados genômicos.\n",
    "\n",
    "A partir dos resultados de execução, notamos que a abordagem híbrida permite um processamento eficiente e organizado das sequências de DNA. A criação de arquivos de saída separados também permite o rastreamento individual dos resultados, o que pode ser útil para futuros trabalhos de análise e interpretação dos dados gerados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 3: Trabalhando com aminoácidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código da implementação do Exercício 3:\n",
    "\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <fstream>\n",
    "#include <mpi.h>\n",
    "#include <omp.h>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "#include <filesystem>\n",
    "\n",
    "namespace fs = std::filesystem;\n",
    "\n",
    "// Função para contar ocorrências do códon de início \"AUG\" em uma sequência de RNA\n",
    "int countStartCodons(const std::string& sequence) {\n",
    "    int count = 0;\n",
    "    #pragma omp parallel for reduction(+:count)\n",
    "    for (size_t i = 0; i <= sequence.size() - 3; i++) {\n",
    "        if (sequence.substr(i, 3) == \"AUG\") {\n",
    "            count++;\n",
    "        }\n",
    "    }\n",
    "    return count;\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "    // Caminho dos arquivos de RNA gerados no exercício anterior\n",
    "    std::string directory = \"../ex2/output\";\n",
    "    std::vector<std::string> rnaFiles;\n",
    "\n",
    "    // Apenas o processo principal (rank 0) lista os arquivos de RNA\n",
    "    if (rank == 0) {\n",
    "        for (const auto& entry : fs::directory_iterator(directory)) {\n",
    "            if (entry.path().extension() == \".fa\") {\n",
    "                rnaFiles.push_back(entry.path().string());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Broadcast do número de arquivos RNA para todos os processos\n",
    "    int numFiles = rnaFiles.size();\n",
    "    MPI_Bcast(&numFiles, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    // Distribuir a lista de arquivos RNA para todos os processos\n",
    "    if (rank != 0) {\n",
    "        rnaFiles.resize(numFiles);\n",
    "    }\n",
    "    for (int i = 0; i < numFiles; i++) {\n",
    "        int length = (rank == 0) ? rnaFiles[i].size() : 0;\n",
    "        MPI_Bcast(&length, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "        if (rank != 0) {\n",
    "            rnaFiles[i].resize(length);\n",
    "        }\n",
    "        MPI_Bcast(&rnaFiles[i][0], length, MPI_CHAR, 0, MPI_COMM_WORLD);\n",
    "    }\n",
    "\n",
    "    double startTime = MPI_Wtime();\n",
    "\n",
    "    // Contagem de códons de início local\n",
    "    int localCount = 0;\n",
    "    for (int i = rank; i < numFiles; i += size) {\n",
    "        std::ifstream file(rnaFiles[i]);\n",
    "        if (!file.is_open()) {\n",
    "            std::cerr << \"Erro ao abrir o arquivo: \" << rnaFiles[i] << std::endl;\n",
    "            continue;\n",
    "        }\n",
    "\n",
    "        std::string line, sequence;\n",
    "        while (std::getline(file, line)) {\n",
    "            if (line[0] != '>') {\n",
    "                sequence += line;  // Concatenar a sequência de RNA\n",
    "            }\n",
    "        }\n",
    "        file.close();\n",
    "\n",
    "        // Contar códons de início \"AUG\" na sequência\n",
    "        localCount += countStartCodons(sequence);\n",
    "        std::cout << \"Processo \" << rank << \" encontrou \" << localCount << \" códons 'AUG' no arquivo: \" << rnaFiles[i] << std::endl;\n",
    "    }\n",
    "\n",
    "    // Reduzir as contagens locais em uma soma global\n",
    "    int globalCount = 0;\n",
    "    MPI_Reduce(&localCount, &globalCount, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    double endTime = MPI_Wtime();\n",
    "    double executionTime = endTime - startTime;\n",
    "\n",
    "    if (rank == 0) {\n",
    "        std::cout << \"Total de proteínas inicializadas (códons 'AUG'): \" << globalCount << std::endl;\n",
    "        std::cout << \"Tempo total de execução (Híbrido MPI + OpenMP): \" << executionTime << \" segundos\" << std::endl;\n",
    "    }\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados:\n",
    "\n",
    "```\n",
    "exercicio 3\n",
    "Processo 0 encontrou 556106 códons 'AUG' no arquivo: ../ex2/output/chr16.subst.rna.fa\n",
    "Processo 2 encontrou 627452 códons 'AUG' no arquivo: ../ex2/output/chr15.subst.rna.fa\n",
    "Processo 3 encontrou 682538 códons 'AUG' no arquivo: ../ex2/output/chr14.subst.rna.fa\n",
    "Processo 1 encontrou 823937 códons 'AUG' no arquivo: ../ex2/output/chr13.subst.rna.fa\n",
    "Processo 0 encontrou 2074595 códons 'AUG' no arquivo: ../ex2/output/chr4.subst.rna.fa\n",
    "Processo 0 encontrou 2509475 códons 'AUG' no arquivo: ../ex2/output/chr20.subst.rna.fa\n",
    "Processo 1 encontrou 2373849 códons 'AUG' no arquivo: ../ex2/output/chr3.subst.rna.fa\n",
    "Processo 2 encontrou 2318682 códons 'AUG' no arquivo: ../ex2/output/chr1.subst.rna.fa\n",
    "Processo 3 encontrou 2630081 códons 'AUG' no arquivo: ../ex2/output/chr2.subst.rna.fa\n",
    "Processo 1 encontrou 2673515 códons 'AUG' no arquivo: ../ex2/output/chr19.subst.rna.fa\n",
    "Processo 0 encontrou 3148866 códons 'AUG' no arquivo: ../ex2/output/chr18.subst.rna.fa\n",
    "Processo 3 encontrou 3176033 códons 'AUG' no arquivo: ../ex2/output/chr17.subst.rna.fa\n",
    "Processo 0 encontrou 3381504 códons 'AUG' no arquivo: ../ex2/output/chr22.subst.rna.fa\n",
    "Processo 2 encontrou 3441377 códons 'AUG' no arquivo: ../ex2/output/chr8.subst.rna.fa\n",
    "Processo 2 encontrou 3727641 códons 'AUG' no arquivo: ../ex2/output/chr21.subst.rna.fa\n",
    "Processo 1 encontrou 3886061 códons 'AUG' no arquivo: ../ex2/output/chr7.subst.rna.fa\n",
    "Processo 3 encontrou 4161277 códons 'AUG' no arquivo: ../ex2/output/chr12.subst.rna.fa\n",
    "Processo 0 encontrou 4305777 códons 'AUG' no arquivo: ../ex2/output/chr9.subst.rna.fa\n",
    "Processo 2 encontrou 5088472 códons 'AUG' no arquivo: ../ex2/output/chr6.subst.rna.fa\n",
    "Processo 3 encontrou 5133365 códons 'AUG' no arquivo: ../ex2/output/chr11.subst.rna.fa\n",
    "Processo 1 encontrou 5315665 códons 'AUG' no arquivo: ../ex2/output/chr5.subst.rna.fa\n",
    "Processo 1 encontrou 6367060 códons 'AUG' no arquivo: ../ex2/output/chr10.subst.rna.fa\n",
    "Total de proteínas inicializadas (códons 'AUG'): 20894674\n",
    "Tempo total de execução (Híbrido MPI + OpenMP): 35.5556 segundos\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3: Contagem de Proteínas Inicializadas\n",
    "\n",
    "**Objetivo**: O objetivo deste exercício foi contar o número de proteínas potencialmente inicializadas, identificando o códon de início `\"AUG\"` nas sequências de RNA geradas no exercício anterior. Essa contagem foi realizada em paralelo, utilizando uma implementação híbrida de MPI e OpenMP, com o intuito de otimizar o tempo de processamento e distribuir a carga entre diferentes processos e threads.\n",
    "\n",
    "**Implementação**: \n",
    "1. **Distribuição de Arquivos com MPI**: Cada processo MPI foi designado para processar uma quantidade específica de arquivos de RNA, dividindo-os de maneira equilibrada. Com isso, processos diferentes trabalhavam simultaneamente em arquivos distintos, aproveitando melhor os recursos de processamento distribuído.\n",
    "   \n",
    "2. **Paralelização com OpenMP**: Dentro de cada processo MPI, utilizamos OpenMP para dividir a carga de trabalho entre as threads, facilitando a busca pelo códon `\"AUG\"` em grandes sequências de RNA. Essa divisão interna permitiu que a contagem fosse realizada em paralelo, dentro de cada arquivo.\n",
    "\n",
    "3. **Agregação dos Resultados**: Ao final do processamento, cada processo MPI tinha uma contagem local de códons `\"AUG\"`. Usamos a função `MPI_Reduce` para somar as contagens locais em uma contagem global no processo principal, obtendo o total de proteínas inicializadas em todos os arquivos.\n",
    "\n",
    "**Resultados**:\n",
    "- **Contagem Total**: A contagem total de proteínas inicializadas, ou códons `\"AUG\"` encontrados, foi de **20.894.674** em todos os arquivos.\n",
    "- **Tempo de Execução**: A execução completa do exercício levou aproximadamente **35,56 segundos** com a abordagem híbrida.\n",
    "\n",
    "**Análise dos Resultados**:\n",
    "A abordagem híbrida de MPI e OpenMP se mostrou eficaz na redução do tempo de execução para o processamento de grandes quantidades de dados de RNA. A paralelização com MPI garantiu que diferentes arquivos fossem processados simultaneamente, enquanto a utilização de OpenMP permitiu uma análise rápida e eficiente dentro de cada arquivo. Esse método foi vantajoso especialmente pela quantidade de dados envolvidos, distribuindo tanto a carga de I/O quanto o processamento entre os núcleos.\n",
    "\n",
    "**Considerações Técnicas**:\n",
    "- A divisão balanceada dos arquivos entre processos MPI foi essencial para evitar sobrecarga em processos específicos e assegurar um uso uniforme dos recursos.\n",
    "- Como cada arquivo foi processado de forma independente, foi possível observar a contagem de códons `\"AUG\"` para cada arquivo individual, com o output detalhado indicando qual processo processou cada arquivo. Essa distribuição é fundamental para monitorar o desempenho e garantir a precisão dos resultados.\n",
    "\n",
    "**Conclusão**:\n",
    "A implementação híbrida (MPI + OpenMP) proporcionou uma contagem rápida e escalável dos códons de início `\"AUG\"` em sequências de RNA, revelando uma distribuição eficiente do processamento e oferecendo insights sobre o potencial de paralelização para tarefas de bioinformática. Este exercício destaca a vantagem do uso combinado de MPI e OpenMP para processamento em larga escala de dados genômicos, fornecendo uma base sólida para futuros projetos de análise em bioinformática.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
