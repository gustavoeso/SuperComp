{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício 1: Cálculo do Quadrado de cada Elemento da Matriz**\n",
    "\n",
    "| Modo               | Tempo de Execução (segundos) |\n",
    "|--------------------|------------------------------|\n",
    "| Com OpenMP        | 0.000848752                  |\n",
    "| Sem OpenMP        | 0.00107542                   |\n",
    "\n",
    "Observação: A versão com paralelização em OpenMP apresenta um tempo de execução menor, indicando uma melhora no desempenho devido à paralelização local."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise do Exercício 2\n",
    "Ao dividir uma matriz ou vetor entre múltiplos processos com MPI, `MPI_Scatter` distribui partes iguais dos dados para cada processo. No entanto, quando o total de elementos não é divisível pelo número de processos, alguns processos podem acabar recebendo menos elementos. Esse desequilíbrio na distribuição de carga pode impactar a eficiência do programa, especialmente em aplicações onde o balanceamento de carga é crucial para um desempenho ótimo.\n",
    "\n",
    "Esse problema é conhecido como **desbalanceamento de carga**, e ocorre quando alguns processos têm mais trabalho que outros, resultando em tempos de execução diferentes entre os processos. Na prática, o processo que recebe mais dados pode levar mais tempo para concluir sua parte, deixando os outros processos ociosos, o que diminui o ganho de eficiência da paralelização.\n",
    "\n",
    "### Como Mitigar o Desbalanceamento de Carga?\n",
    "Uma estratégia para mitigar esse problema é ajustar manualmente a divisão de dados. Pode-se, por exemplo, distribuir um elemento adicional aos primeiros processos até que todos os elementos sejam alocados. Essa abordagem, chamada **balanceamento dinâmico de carga**, garante que cada processo receba aproximadamente a mesma quantidade de trabalho. Além disso, em casos onde é fundamental que cada processo tenha exatamente o mesmo número de dados, é possível incluir um \"padding\" (elementos fictícios) para completar o tamanho da matriz, facilitando a divisão igual entre os processos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício 3: Cálculo Distribuído da Média de uma Matriz**\n",
    "\n",
    "Matriz gerada no processo 0:\n",
    "```\n",
    "8 6 2 6\n",
    "8 0 3 2\n",
    "6 6 9 7\n",
    "8 3 3 9\n",
    "```\n",
    "\n",
    "- **Soma total da matriz**: 86\n",
    "- **Média dos elementos da matriz**: 5.375\n",
    "\n",
    "Observação: A soma e a média foram calculadas distribuindo as operações entre processos MPI, com uso de OpenMP para cálculo paralelo das somas parciais em cada processo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercicio 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício 4: Busca em Vetor Distribuído**\n",
    "\n",
    "Vetor gerado no processo 0:\n",
    "```\n",
    "7 3 3 7 6 2 0 8 5 0 8 3 2 8 1 8 2 1 3 3 0 0 5 6 0 2 9 2 1 6 1 8 1 6 7 7 0 8 7 5 0 6 0 2 6 2 2 8 3 5 3 3 7 1 1 0 3 3 2 4 9 5 4 0 4 4 0 4 2 7 2 4 5 2 8 2 6 0 2 1 7 6 7 4 7 8 4 2 1 9 8 2 6 4 3 0 8 3 7 2\n",
    "```\n",
    "\n",
    "- **Posições do valor 5 encontradas em**: 8, 22, 39, 49, 72, 61\n",
    "\n",
    "Observação: A busca pelo valor 5 foi realizada de forma paralela com MPI, distribuindo partes do vetor entre os processos e usando OpenMP para a busca em cada subvetor. As posições onde o valor foi encontrado foram coletadas e exibidas."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
